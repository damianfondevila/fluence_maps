{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_evaluate",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNWjrnxdfpmwiaURnN8MH+R"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n_PAVFGnZDx",
        "colab_type": "text"
      },
      "source": [
        "# Compute predictions on a TF dataset using an stored .h5 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A85nWqMEnKPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5cb5e0de-276c-4bff-e75b-7e34d45a6a29"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd -q '/content'\n",
        "if os.path.exists('fluence_maps'):\n",
        "  !rm -fr fluence_maps\n",
        "\n",
        "GIT_USERNAME = \"pablojrios\"\n",
        "GIT_TOKEN = \"1d88a0b85d2b00a03796e4d8b7e5f7b249b12f9b\"\n",
        "!git clone -s https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/fluence_maps.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fluence_maps'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 112 (delta 58), reused 37 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (112/112), 271.41 KiB | 1.07 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LvLPLr5n_yJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d13d3d17-7358-4127-ed97-420f1ade0b8a"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "%cd '/content/fluence_maps'\n",
        "from util.dataset import _tfrecord_dataset_type_from_folder, _parse_jpeg_image_function\n",
        "from util.preprocess import rescale_min_1_to_1\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fluence_maps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN_LGyd6pWeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7c93112-6a14-48e8-82fa-d52cbc501d30"
      },
      "source": [
        "print('Tensorflow version = {}'.format(tf.__version__))\n",
        "print('Executing eagerly = {}'.format(tf.executing_eagerly()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version = 2.2.0-rc4\n",
            "Executing eagerly = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzL176Gmq_KA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6ac58a6c-9c2c-4d41-ad0c-0e829079a8ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWlKtT6Kpbsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#============================DEFINE YOUR ARGUMENTS==============================\n",
        "# base data directory\n",
        "ARG_DATASET_DIR='/content/drive/My Drive/Healthcare/Radioterapia/data/ciolaplata'\n",
        "# folder under ARG_DATASET_DIR path.\n",
        "ARG_TFDATASET_FOLDER='tfds.2019.pablo'\n",
        "ARG_MODEL_NAME = '1588128880'\n",
        "ARG_SAVED_MODEL_DIR = '/content/fluence_maps/tmp/saved_models/{}.h5'.format(ARG_MODEL_NAME)\n",
        "ARG_PART = 'train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2-IdOEGqmU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f3b2177-0028-44ca-d5fa-16960a4a4fcf"
      },
      "source": [
        "tfdataset_dir = os.path.join(ARG_DATASET_DIR, ARG_TFDATASET_FOLDER)\n",
        "raw_test = _tfrecord_dataset_type_from_folder(tfdataset_dir, ARG_PART)\n",
        "print(raw_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TFRecordDatasetV2 shapes: (), types: tf.string>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfTOOGlJrYIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d80d5413-9f0d-495f-f9e3-042a4fbb47c8"
      },
      "source": [
        "# Apply this function to each item in the dataset using the map method:\n",
        "num_workers = 8\n",
        "IMG_SIZE = 256\n",
        "normalization_fn = rescale_min_1_to_1\n",
        "test = raw_test.map(lambda e: _parse_jpeg_image_function(e, IMG_SIZE, normalization_fn), num_parallel_calls=num_workers)\n",
        "print(test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ParallelMapDataset shapes: ((256, 256, 3), (), ()), types: (tf.float32, tf.float32, tf.string)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yG0Vf93rmOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5d7840e-5c6c-462d-b728-ff7b67139b35"
      },
      "source": [
        "gamma_values = test.map(lambda image, gamma, filename: gamma)\n",
        "gamma_values = np.array(list(gamma_values.as_numpy_iterator()))\n",
        "BATCH_SIZE = 32 # mae puede variar según batch size.\n",
        "test_batches = test.batch(BATCH_SIZE)\n",
        "print(test_batches)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 256, 256, 3), (None,), (None,)), types: (tf.float32, tf.float32, tf.string)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjrt80mNr0a4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load model\n",
        "loaded_model = tf.keras.models.load_model(ARG_SAVED_MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEaSI7qj86Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate test set with the loaded model\n",
        "tmp_test_batches = test_batches.map(lambda image, gamma, filename: (image, gamma))\n",
        "print(tmp_test_batches)\n",
        "loss, mse = reloaded_model.evaluate(tmp_test_batches, workers=num_workers, verbose=0)\n",
        "print('\\n\\nLoaded model, test loss: {:5.4f}'.format(loss))\n",
        "print('Loaded model, test mse: {:5.4f}'.format(mse))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctN7LhzY9I3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions\n",
        "predictions = reloaded_model.predict(tmp_test_batches)\n",
        "# from (1121,1) to (1121,); ie.: ndim = 2 to ndim = 1\n",
        "predictions = predictions.reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkoSrJyh9jtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_test_batches = test.map(lambda image, gamma, filename: (filename, gamma))\n",
        "list = [(filename.numpy().decode('utf-8'), gamma.numpy()) for filename, gamma in tmp_test_batches]\n",
        "list2 = [(e[0], e[1], p) for e, p in zip(list, predictions)]\n",
        "\n",
        "# armar un pandas dataframe con el test set completo\n",
        "df = pd.DataFrame(list2, columns=['filename', 'actual gamma', 'predicted gamma'])\n",
        "df.to_csv('predicted_gamma_{}.{}.csv'.format(MODEL_NAME, part), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}